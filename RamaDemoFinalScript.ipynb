{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RamaDemoFinalScript.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdotkihm4MVq"
      },
      "source": [
        "!pip install torch-mtcnn  #algo for face detection"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lM_MZDD4UmP"
      },
      "source": [
        "from torch_mtcnn import detect_faces #IMPORT THE ABOVE DOWNLOADED MODULE\n",
        "#NECESSARY IMPORTS\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaE2_j064Wh4"
      },
      "source": [
        "from PIL import Image \n",
        "\n",
        "image_new = Image.open('mask.jpg')#JPG IMAGE INPUT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tha-DqkW4hVE"
      },
      "source": [
        "image_save = cv2.imread('mask.jpg')#SAVE JPG INPUT\n",
        "\n",
        "bounding_boxes, landmarks = detect_faces(image_new)#DETECT FACES GET THE BOUNDING BOX COORDINATES"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J23K1lmq43jT"
      },
      "source": [
        "face_image = image_processing[top:bottom, left:right]  #Cropping OUT FACE FROM PHOTO\n",
        "\n",
        "cv2.imwrite('/content/drive/My Drive/APS 360/TestingImages/nomask/'+str(count)+'.jpg',face_image) #STORE FACE INTO APPROPRAITE DIRECTORY\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dat2XMWp4s15"
      },
      "source": [
        "\n",
        "#NEEDED TRANSFORMS\n",
        "transform = transforms.Compose([transforms.Resize((128,128)),\n",
        "                                   transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])\n",
        "\n",
        "#LOAD FACE FROM APPROPRIATE DIRECTORY\n",
        "data = torchvision.datasets.ImageFolder(root='/content/drive/My Drive/APS 360/TestingImages',transform=transform) \n",
        "#DATA LOADER -LAST PROCESSING STEP\n",
        "test_loader=torch.utils.data.DataLoader(data,batch_size=1,shuffle=True) \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WUMsfz65Jh-"
      },
      "source": [
        "#ACTUAL MODEL CALLS\n",
        "\n",
        "#MODEL PART1 FEATURE COMPUTATION\n",
        "\n",
        "from torchvision import models\n",
        "\n",
        "googlenet = models.googlenet(pretrained=True) #GET GOOGLE NET\n",
        "\n",
        "#We remove last linear layer because we will be using our own classifier\n",
        "googlenet.fc = nn.Identity()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PzgqFZd5tj7"
      },
      "source": [
        "#MODEL PART 2\n",
        "#OUR TRAINED ANN\n",
        "#TRANSFER LEARNING+FINE TUNING\n",
        "\n",
        "#We will try dropout to reduce overfit\n",
        "#Now we set up a neural net classifier on top of the ResNet-this classifier uses the features computed from ResNet and traines on top of it \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "torch.manual_seed(1) # set the random seed\n",
        "\n",
        "class Classifier_withDropout(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Classifier_withDropout, self).__init__()\n",
        "        self.layer1 = nn.Linear(512,1000)  #Similar to ResNet \n",
        "        self.layer2 = nn.Linear(1000,2)\n",
        "        self.dropout = nn.Dropout(0.2) # drop out layer with 20% dropped out neuron-To reduce overfitting!\n",
        "\n",
        "\n",
        "       \n",
        "    def forward(self, img):\n",
        "        flattened = img.view(-1, 512)\n",
        "        activation1 = self.layer1(flattened)\n",
        "        activation1 = F.relu(activation1)\n",
        "        activation2 = self.dropout(self.layer2(activation1))\n",
        "        # activation2 = F.relu(activation2)\n",
        "        # activation3 = self.layer3(activation2)\n",
        "\n",
        "        activation2 = activation2.squeeze(1) # Flatten to [batch_size]\n",
        "\n",
        "\n",
        "        return activation2\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#LOAD THE SAVED MODEL\n",
        "\n",
        "saved_model = Classifier_withDropout() #INSTANTIATE\n",
        "saved_model.load_state_dict((torch.load(\"model_TransferLearning_GoogleNet_bs128_lr0.001_epoch10\")))#LOAD\n",
        "saved_model.eval() #MUST TO REMOVE DROPOUT\n",
        "saved_model=saved_model.cuda()#GPU \n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rH77Luop5cGc"
      },
      "source": [
        "#LOOP OVER EVERY IMAGE IN TEST LOADER\n",
        "\n",
        "for images, labels in test_loader:\n",
        "       features = googlenet(images) #COMPUTE FEATURES FOR EACH IMAGE USING GOOGLE NET\n",
        "       #This line is NEEDED OTHER WISE ERRORS IN BACK PROPAGATION!!\n",
        "       features_tensor = torch.from_numpy(features.detach().cpu().numpy())\n",
        "       output=saved_model(features_tensor)#PASS TO THE LOADED MODEL TO MAKE PREDICTION\n",
        "       pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "       title=\"\"\n",
        "       if(pred==0):\n",
        "          title='masked'\n",
        "       else:\n",
        "          title='no mask'\n",
        "       plt.imshow(face_image)\n",
        "       plt.title(title)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}